{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVIL1jpMbHRl",
        "outputId": "004220be-de36-4ab8-9b47-b0980ece0e41"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Parameters\n",
        "MAX_LEN_EN = 40\n",
        "MAX_LEN_HI = 40\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 512\n",
        "ENC_UNITS = 512\n",
        "DEC_UNITS = ENC_UNITS * 2 \n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Special tokens\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "START_TOKEN = \"<start>\"\n",
        "END_TOKEN = \"<end>\"\n",
        "special_tokens = [PAD_TOKEN, UNK_TOKEN, START_TOKEN, END_TOKEN]\n",
        "\n",
        "# 1. Load dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"cfilt/iitb-english-hindi\", split=\"train[:2%]\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoLOCD5ogf40",
        "outputId": "50162e78-acf1-416e-a231-c7fe2d610285"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['translation'],\n",
              "    num_rows: 33182\n",
              "})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TJq4iseb5iV",
        "outputId": "4ba706d3-7055-4937-96c1-9bcb203eb277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: Give your application an accessibility workout\n",
            "Hindi: अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें\n",
            "==============================\n",
            "English: Accerciser Accessibility Explorer\n",
            "Hindi: एक्सेर्साइसर पहुंचनीयता अन्वेषक\n",
            "==============================\n",
            "English: The default plugin layout for the bottom panel\n",
            "Hindi: निचले पटल के लिए डिफोल्ट प्लग-इन खाका\n",
            "==============================\n",
            "English: The default plugin layout for the top panel\n",
            "Hindi: ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका\n",
            "==============================\n",
            "English: A list of plugins that are disabled by default\n",
            "Hindi: उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "  print(f\"English: {dataset[i]['translation']['en']}\")\n",
        "  print(f\"Hindi: {dataset[i]['translation']['hi']}\")\n",
        "  print(\"=\"*30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vLeWWC9zbygs"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s,.!?'-]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "def preprocess_sentence(sentence, language='hi'):\n",
        "    sentence = clean_text(sentence)\n",
        "    tokens = tokenize(sentence)\n",
        "    if language == 'en':\n",
        "        tokens = [START_TOKEN] + tokens + [END_TOKEN]\n",
        "    return tokens\n",
        "\n",
        "def build_vocab(tokenized_sentences, vocab_size=None):\n",
        "    counter = Counter()\n",
        "    for sent in tokenized_sentences:\n",
        "        counter.update(sent)\n",
        "    vocab = special_tokens + [word for word, freq in counter.most_common() if word not in special_tokens]\n",
        "    if vocab_size:\n",
        "        vocab = vocab[:vocab_size]\n",
        "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "    return word2idx\n",
        "\n",
        "def encode_sentence(tokens, word2idx, max_len):\n",
        "    encoded = [word2idx.get(token, word2idx[UNK_TOKEN]) for token in tokens]\n",
        "    if len(encoded) > max_len:\n",
        "        encoded = encoded[:max_len]\n",
        "    else:\n",
        "        encoded += [word2idx[PAD_TOKEN]] * (max_len - len(encoded))\n",
        "    return encoded\n",
        "\n",
        "# Prepare sentences\n",
        "english_sentences = [example['translation']['en'] for example in dataset]\n",
        "hindi_sentences = [example['translation']['hi'] for example in dataset]\n",
        "\n",
        "tokenized_en = [preprocess_sentence(s, 'en') for s in english_sentences]\n",
        "tokenized_hi = [preprocess_sentence(s, 'hi') for s in hindi_sentences]\n",
        "\n",
        "en_vocab = build_vocab(tokenized_en)\n",
        "hi_vocab = build_vocab(tokenized_hi)\n",
        "\n",
        "encoded_en = np.array([encode_sentence(s, en_vocab, MAX_LEN_EN) for s in tokenized_en])\n",
        "encoded_hi = np.array([encode_sentence(s, hi_vocab, MAX_LEN_HI) for s in tokenized_hi])\n",
        "\n",
        "# Prepare tf.data.Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((encoded_en, encoded_hi))\n",
        "dataset = dataset.shuffle(10000).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Indices of special tokens for loss masking\n",
        "PAD_IDX = en_vocab[PAD_TOKEN]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(query_with_time_axis)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super().__init__()\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.bi_lstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(enc_units, return_sequences=True, return_state=True)\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, forward_h, forward_c, backward_h, backward_c = self.bi_lstm(x)\n",
        "        state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "        state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
        "        return output, state_h, state_c\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super().__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True, return_state=True)\n",
        "        self.attention = BahdanauAttention(dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, hidden, cell, enc_output):\n",
        "        x = self.embedding(x)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state_h, state_c = self.lstm(x, initial_state=[hidden, cell])\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state_h, state_c, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node encoder_3_1/embedding_6_1/GatherV2 defined at (most recent call last):\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\715884765.py\", line 41, in <module>\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\715884765.py\", line 20, in train_step\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\1409500457.py\", line 26, in call\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 150, in call\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 5795, in take\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2340, in take\n\nindices[62,3] = 870 is not in [0, 728)\n\t [[{{node encoder_3_1/embedding_6_1/GatherV2}}]] [Op:__inference_train_step_60822]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[33], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (enc_batch, dec_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[1;32m---> 41\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;241m/\u001b[39m(batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node encoder_3_1/embedding_6_1/GatherV2 defined at (most recent call last):\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"C:\\Users\\EDWIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\715884765.py\", line 41, in <module>\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\715884765.py\", line 20, in train_step\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\1409500457.py\", line 26, in call\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 150, in call\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 5795, in take\n\n  File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2340, in take\n\nindices[62,3] = 870 is not in [0, 728)\n\t [[{{node encoder_3_1/embedding_6_1/GatherV2}}]] [Op:__inference_train_step_60822]"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(len(hi_vocab), EMBEDDING_DIM, ENC_UNITS)\n",
        "decoder = Decoder(len(en_vocab), EMBEDDING_DIM, DEC_UNITS)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, PAD_IDX))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "@tf.function\n",
        "def train_step(enc_input, dec_target):\n",
        "    loss = 0\n",
        "    batch_size = enc_input.shape[0]\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden, enc_cell = encoder(enc_input)\n",
        "        dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "\n",
        "        dec_input = tf.expand_dims([en_vocab[START_TOKEN]] * batch_size, 1)\n",
        "\n",
        "        for t in range(1, dec_target.shape[1]):\n",
        "            predictions, dec_hidden, dec_cell, _ = decoder(dec_input, dec_hidden, dec_cell, enc_output)\n",
        "            loss += loss_function(dec_target[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(dec_target[:, t], 1)\n",
        "\n",
        "    batch_loss = loss / int(dec_target.shape[1] - 1)\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for batch, (enc_batch, dec_batch) in enumerate(dataset):\n",
        "        batch_loss = train_step(enc_batch, dec_batch)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss {total_loss/(batch+1):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qZTiDcg_Xgy_"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super().__init__()\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.bi_lstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(enc_units, return_sequences=True, return_state=True)\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, forward_h, forward_c, backward_h, backward_c = self.bi_lstm(x)\n",
        "        state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "        state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
        "        return output, state_h, state_c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8EB7zHhWXjcH"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super().__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True, return_state=True)\n",
        "        self.attention = BahdanauAttention(dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, hidden, cell, enc_output):\n",
        "        x = self.embedding(x)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state_h, state_c = self.lstm(x, initial_state=[hidden, cell])\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state_h, state_c, attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_K_uw0LgXpsW"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(len(hi_vocab), EMBEDDING_DIM, ENC_UNITS)\n",
        "decoder = Decoder(len(en_vocab), EMBEDDING_DIM, DEC_UNITS)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "PAD_IDX = en_vocab[PAD_TOKEN]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DVKZglrHXs0p"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(enc_input, dec_target):\n",
        "    loss = 0\n",
        "    batch_size = enc_input.shape[0]\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden, enc_cell = encoder(enc_input)\n",
        "        dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "\n",
        "        # Decoder input starts with English <START> token\n",
        "        dec_input = tf.expand_dims([en_vocab[START_TOKEN]] * batch_size, 1)\n",
        "\n",
        "        for t in range(1, dec_target.shape[1]):\n",
        "            predictions, dec_hidden, dec_cell, _ = decoder(dec_input, dec_hidden, dec_cell, enc_output)\n",
        "            loss += loss_function(dec_target[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(dec_target[:, t], 1)\n",
        "\n",
        "    batch_loss = loss / int(dec_target.shape[1] - 1)\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IK2LwnVsXrHz"
      },
      "outputs": [],
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, PAD_IDX))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D0wRQ4pfYE02"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\3939651672.py\", line 14, in train_step  *\n        predictions, dec_hidden, dec_cell, _ = decoder(dec_input, dec_hidden, dec_cell, enc_output)\n    File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\1823708170.py\", line 14, in call\n        output, state_h, state_c = self.lstm(x, initial_state=[hidden, cell])\n\n    ValueError: Exception encountered when calling LSTMCell.call().\n    \n    \u001b[1mDimensions must be equal, but are 1024 and 512 for '{{node decoder_1/lstm_1_1/lstm_cell_1/MatMul_1}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](encoder_1/concatenate_2_1/concat, decoder_1/lstm_1_1/lstm_cell_1/Cast_1/ReadVariableOp)' with input shapes: [64,1024], [512,2048].\u001b[0m\n    \n    Arguments received by LSTMCell.call():\n      • inputs=tf.Tensor(shape=(64, 1536), dtype=float32)\n      • states=('tf.Tensor(shape=(64, 1024), dtype=float32)', 'tf.Tensor(shape=(64, 1024), dtype=float32)')\n      • training=False\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (enc_batch, dec_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[1;32m----> 4\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;241m/\u001b[39m(batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileiwb_j8ep.py:34\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(enc_input, dec_target)\u001b[0m\n\u001b[0;32m     32\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m     t \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_target\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdec_cell\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdec_hidden\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdec_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(loss) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mint\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(dec_target)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     36\u001b[0m variables \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(encoder)\u001b[38;5;241m.\u001b[39mtrainable_variables \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(decoder)\u001b[38;5;241m.\u001b[39mtrainable_variables\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileiwb_j8ep.py:27\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step.<locals>.loop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m dec_hidden, dec_input, loss, dec_cell\n\u001b[0;32m     26\u001b[0m t \u001b[38;5;241m=\u001b[39m itr\n\u001b[1;32m---> 27\u001b[0m (predictions, dec_hidden, dec_cell, _) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_hidden\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_cell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(loss)\n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(loss_function, (dec_target[:, t], predictions), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "Cell \u001b[1;32mIn[7], line 14\u001b[0m, in \u001b[0;36mDecoder.call\u001b[1;34m(self, x, hidden, cell, enc_output)\u001b[0m\n\u001b[0;32m     12\u001b[0m context_vector, attention_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(hidden, enc_output)\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([tf\u001b[38;5;241m.\u001b[39mexpand_dims(context_vector, \u001b[38;5;241m1\u001b[39m), x], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m output, state_h, state_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(output, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output)\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\3939651672.py\", line 14, in train_step  *\n        predictions, dec_hidden, dec_cell, _ = decoder(dec_input, dec_hidden, dec_cell, enc_output)\n    File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\1823708170.py\", line 14, in call\n        output, state_h, state_c = self.lstm(x, initial_state=[hidden, cell])\n\n    ValueError: Exception encountered when calling LSTMCell.call().\n    \n    \u001b[1mDimensions must be equal, but are 1024 and 512 for '{{node decoder_1/lstm_1_1/lstm_cell_1/MatMul_1}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](encoder_1/concatenate_2_1/concat, decoder_1/lstm_1_1/lstm_cell_1/Cast_1/ReadVariableOp)' with input shapes: [64,1024], [512,2048].\u001b[0m\n    \n    Arguments received by LSTMCell.call():\n      • inputs=tf.Tensor(shape=(64, 1536), dtype=float32)\n      • states=('tf.Tensor(shape=(64, 1024), dtype=float32)', 'tf.Tensor(shape=(64, 1024), dtype=float32)')\n      • training=False\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for batch, (enc_batch, dec_batch) in enumerate(dataset):\n",
        "        batch_loss = train_step(enc_batch, dec_batch)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss {total_loss/(batch+1):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\EDWIN\\.cache\\huggingface\\hub\\models--ai4bharat--indic-bert. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 1. Load Dataset\n",
        "dataset = load_dataset(\"cfilt/iitb-english-hindi\", split=\"train[:2%]\")\n",
        "src_texts = [x['translation']['en'] for x in dataset]\n",
        "tgt_texts = [x['translation']['hi'] for x in dataset]\n",
        "\n",
        "# 2. Tokenization\n",
        "src_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "tgt_tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_src_len, max_tgt_len = 40, 40\n",
        "\n",
        "def encode(texts, tokenizer, max_len):\n",
        "    tokens = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"np\")\n",
        "    return tokens['input_ids']\n",
        "\n",
        "src_sequences = encode(src_texts, src_tokenizer, max_src_len)\n",
        "tgt_sequences = encode(tgt_texts, tgt_tokenizer, max_tgt_len)\n",
        "\n",
        "# Prepare decoder input (shifted right)\n",
        "def shift_right(arr):\n",
        "    pad_id = tgt_tokenizer.pad_token_id\n",
        "    sos_id = tgt_tokenizer.cls_token_id if tgt_tokenizer.cls_token_id else tgt_tokenizer.bos_token_id\n",
        "    shifted = np.full_like(arr, pad_id)\n",
        "    shifted[:, 1:] = arr[:, :-1]\n",
        "    shifted[:, 0] = sos_id\n",
        "    return shifted\n",
        "\n",
        "decoder_input = shift_right(tgt_sequences)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((src_sequences, decoder_input), tgt_sequences)).batch(32)\n",
        "\n",
        "# 3. Model hyperparameters\n",
        "ENC_UNITS = 256\n",
        "DEC_UNITS = 256\n",
        "VOCAB_SIZE_SRC = src_tokenizer.vocab_size\n",
        "VOCAB_SIZE_TGT = tgt_tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super().__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(enc_units, return_sequences=True, return_state=True)\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, forward_h, forward_c, backward_h, backward_c = self.bilstm(x)\n",
        "        state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "        state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
        "        return output, state_h, state_c\n",
        "\n",
        "# 5. Attention\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = tf.reduce_sum(attention_weights * values, axis=1)\n",
        "        return context_vector, tf.squeeze(attention_weights, -1)\n",
        "\n",
        "# 6. Decoder\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units):\n",
        "        super().__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.attention = BahdanauAttention(dec_units)\n",
        "        self.lstm = tf.keras.layers.LSTM(dec_units * 2, return_sequences=True, return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # Project encoder states to correct decoder size\n",
        "        self.state_proj_h = tf.keras.layers.Dense(dec_units * 2)\n",
        "        self.state_proj_c = tf.keras.layers.Dense(dec_units * 2)\n",
        "\n",
        "    def call(self, x, hidden, cell, enc_output):\n",
        "        context_vector, attn_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        context_vector = tf.expand_dims(context_vector, 1)\n",
        "        x = tf.concat([context_vector, x], axis=-1)\n",
        "        output, state_h, state_c = self.lstm(x, initial_state=[\n",
        "            self.state_proj_h(hidden), self.state_proj_c(cell)\n",
        "        ])\n",
        "        output = self.fc(output)\n",
        "        return output, state_h, state_c, attn_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\3142741670.py\", line 17, in train_step  *\n        outputs, dec_h, dec_c, attn = decoder(dec_in, dec_h, dec_c, enc_output)\n    File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\3481671349.py\", line 48, in call\n        x = tf.concat([context_vector, x], axis=-1)\n\n    ValueError: Exception encountered when calling Decoder.call().\n    \n    \u001b[1mDimension 1 in both shapes must be equal, but are 1 and 40. Shapes are [32,1] and [32,40]. for '{{node decoder_1_1/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](decoder_1_1/ExpandDims, decoder_1_1/embedding_3_1/GatherV2, decoder_1_1/concat/axis)' with input shapes: [32,1,512], [32,40,128], [] and with computed input tensors: input[2] = <-1>.\u001b[0m\n    \n    Arguments received by Decoder.call():\n      • x=tf.Tensor(shape=(32, 40), dtype=int64)\n      • hidden=tf.Tensor(shape=(32, 512), dtype=float32)\n      • cell=tf.Tensor(shape=(32, 512), dtype=float32)\n      • enc_output=tf.Tensor(shape=(32, 40, 512), dtype=float32)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, ((enc_batch, dec_batch), dec_true) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[1;32m---> 31\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileia051t56.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(enc_in, dec_in, dec_true, encoder, decoder)\u001b[0m\n\u001b[0;32m     11\u001b[0m     (enc_output, enc_h, enc_c) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(encoder), (ag__\u001b[38;5;241m.\u001b[39mld(enc_in),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m     (dec_h, dec_c) \u001b[38;5;241m=\u001b[39m (ag__\u001b[38;5;241m.\u001b[39mld(enc_h), ag__\u001b[38;5;241m.\u001b[39mld(enc_c))\n\u001b[1;32m---> 13\u001b[0m     (outputs, dec_h, dec_c, attn) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_h\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_c\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(loss_function), (ag__\u001b[38;5;241m.\u001b[39mld(dec_true), ag__\u001b[38;5;241m.\u001b[39mld(outputs)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     15\u001b[0m variables \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(encoder)\u001b[38;5;241m.\u001b[39mtrainable_variables \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(decoder)\u001b[38;5;241m.\u001b[39mtrainable_variables\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "Cell \u001b[1;32mIn[17], line 48\u001b[0m, in \u001b[0;36mDecoder.call\u001b[1;34m(self, x, hidden, cell, enc_output)\u001b[0m\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m     47\u001b[0m context_vector \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(context_vector, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m output, state_h, state_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x, initial_state\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_proj_h(hidden), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_proj_c(cell)\n\u001b[0;32m     51\u001b[0m ])\n\u001b[0;32m     52\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output)\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\3142741670.py\", line 17, in train_step  *\n        outputs, dec_h, dec_c, attn = decoder(dec_in, dec_h, dec_c, enc_output)\n    File \"c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\EDWIN\\AppData\\Local\\Temp\\ipykernel_21708\\3481671349.py\", line 48, in call\n        x = tf.concat([context_vector, x], axis=-1)\n\n    ValueError: Exception encountered when calling Decoder.call().\n    \n    \u001b[1mDimension 1 in both shapes must be equal, but are 1 and 40. Shapes are [32,1] and [32,40]. for '{{node decoder_1_1/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](decoder_1_1/ExpandDims, decoder_1_1/embedding_3_1/GatherV2, decoder_1_1/concat/axis)' with input shapes: [32,1,512], [32,40,128], [] and with computed input tensors: input[2] = <-1>.\u001b[0m\n    \n    Arguments received by Decoder.call():\n      • x=tf.Tensor(shape=(32, 40), dtype=int64)\n      • hidden=tf.Tensor(shape=(32, 512), dtype=float32)\n      • cell=tf.Tensor(shape=(32, 512), dtype=float32)\n      • enc_output=tf.Tensor(shape=(32, 40, 512), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "    mask = tf.cast(tf.math.not_equal(y_true, tgt_tokenizer.pad_token_id), dtype=tf.float32)\n",
        "    loss_ = loss_object(y_true, y_pred)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 8. Training step\n",
        "@tf.function\n",
        "def train_step(enc_in, dec_in, dec_true, encoder, decoder):\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_h, enc_c = encoder(enc_in)\n",
        "        dec_h, dec_c = enc_h, enc_c\n",
        "        outputs, dec_h, dec_c, attn = decoder(dec_in, dec_h, dec_c, enc_output)\n",
        "        loss = loss_function(dec_true, outputs)\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(variables, tape.gradient(loss, variables)))\n",
        "    return loss\n",
        "\n",
        "# 9. Training loop\n",
        "encoder = Encoder(VOCAB_SIZE_SRC, 128, ENC_UNITS)\n",
        "decoder = Decoder(VOCAB_SIZE_TGT, 128, DEC_UNITS, ENC_UNITS)\n",
        "\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for batch, ((enc_batch, dec_batch), dec_true) in enumerate(dataset):\n",
        "        batch_loss = train_step(enc_batch, dec_batch, dec_true, encoder, decoder)\n",
        "        total_loss += batch_loss\n",
        "        if batch % 20 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch}, Loss {batch_loss:.4f}\")\n",
        "    print(f\"Epoch {epoch+1} Loss {total_loss/(batch+1):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Jn07_NAcG08"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "    # Preprocess Hindi input\n",
        "    sentence = preprocess_sentence(sentence, 'hi')\n",
        "    encoded = encode_sentence(sentence, hi_vocab, MAX_LEN_HI)\n",
        "    inputs = tf.expand_dims(encoded, 0)\n",
        "\n",
        "    # Encoder\n",
        "    enc_output, enc_hidden, enc_cell = encoder(inputs)\n",
        "    dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "\n",
        "    # Decoder starts with <START> in English vocab\n",
        "    dec_input = tf.expand_dims([en_vocab[START_TOKEN]], 0)\n",
        "    result = []\n",
        "\n",
        "    for t in range(MAX_LEN_EN):\n",
        "        predictions, dec_hidden, dec_cell, attention_weights = decoder(\n",
        "            dec_input, dec_hidden, dec_cell, enc_output\n",
        "        )\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        if predicted_id == en_vocab[END_TOKEN]:\n",
        "            break\n",
        "\n",
        "        result.append(predicted_id)\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    # Convert back to words\n",
        "    inv_en_vocab = {v: k for k, v in en_vocab.items()}\n",
        "    translated_sentence = ' '.join(inv_en_vocab.get(idx, UNK_TOKEN) for idx in result)\n",
        "    return translated_sentence\n",
        "\n",
        "\n",
        "# Example translation\n",
        "test_sentence = \"धन्यवाद\"   # Hindi input\n",
        "print(\"Hindi:\", test_sentence)\n",
        "print(\"English:\", translate(test_sentence))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "931WrRkkro5L"
      },
      "outputs": [],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-hi-en\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFwcCHGBaBap"
      },
      "outputs": [],
      "source": [
        "text = [\"उसका कहा हुआ एक शब्द भी सुनने लायक नहीं है\"]\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "translated = model.generate(**inputs)\n",
        "print(tokenizer.decode(translated[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bHpEnwtDj7Yw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import MarianMTModel, MarianTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "\n",
        "# 1. Load dataset (Hindi to English)\n",
        "dataset = load_dataset('cfilt/iitb-english-hindi', split='train')\n",
        "train_texts = [x['translation']['hi'] for x in dataset]\n",
        "target_texts = [x['translation']['en'] for x in dataset]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\EDWIN\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-hi-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "C:\\Users\\EDWIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Map:   0%|          | 0/1659083 [00:00<?, ? examples/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m targets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n\u001b[1;32m---> 15\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 4. Data collator\u001b[39;00m\n\u001b[0;32m     18\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForSeq2Seq(tokenizer, model\u001b[38;5;241m=\u001b[39mmodel)\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:562\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    560\u001b[0m }\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 562\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    563\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:3327\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[0;32m   3325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3326\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m unprocessed_kwargs \u001b[38;5;129;01min\u001b[39;00m unprocessed_kwargs_per_job:\n\u001b[1;32m-> 3327\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munprocessed_kwargs):\n\u001b[0;32m   3328\u001b[0m                 check_if_shard_done(rank, done, content)\n\u001b[0;32m   3330\u001b[0m \u001b[38;5;66;03m# Avoids PermissionError on Windows (the error: https://github.com/huggingface/datasets/actions/runs/4026734820/jobs/6921621805)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:3683\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[0;32m   3681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3682\u001b[0m     _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 3683\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m iter_outputs(shard_iterable):\n\u001b[0;32m   3684\u001b[0m         num_examples_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(i)\n\u001b[0;32m   3685\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m update_data:\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:3633\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[1;34m(shard_iterable)\u001b[0m\n\u001b[0;32m   3631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3632\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3633\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\EDWIN\\OneDrive\\Documents\\GitHub\\Multilingual-ASR\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:3556\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[1;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[0;32m   3554\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[0;32m   3555\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[38;5;241m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m-> 3556\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
            "Cell \u001b[1;32mIn[21], line 10\u001b[0m, in \u001b[0;36mpreprocess_function\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_function\u001b[39m(batch):\n\u001b[1;32m---> 10\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranslation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, max_length\u001b[38;5;241m=\u001b[39mmax_source_length, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m     targets \u001b[38;5;241m=\u001b[39m tokenizer(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m], max_length\u001b[38;5;241m=\u001b[39mmax_target_length, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m targets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "model_name = \"Helsinki-NLP/opus-mt-hi-en\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "# 3. Tokenize the data\n",
        "max_source_length = 64\n",
        "max_target_length = 64\n",
        "\n",
        "def preprocess_function(batch):\n",
        "    inputs = tokenizer(batch['translation']['hi'], max_length=max_source_length, truncation=True, padding=\"max_length\")\n",
        "    targets = tokenizer(batch['translation']['en'], max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# 4. Data collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./mt-hi-en\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    save_steps=500,\n",
        "    logging_steps=50,\n",
        "    learning_rate=2e-5,\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "# 6. Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# 7. Training\n",
        "trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Saving the model\n",
        "trainer.save_model(\"./mt-hi-en-finetuned\")\n",
        "tokenizer.save_pretrained(\"./mt-hi-en-finetuned\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
